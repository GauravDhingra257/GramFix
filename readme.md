
## Machine Learning Model:

T5-base model:
The Text-to-Text Transfer Transformer(T5) model is based on transfer learning techniques for 
the NLP, it aims to explore what works best and how far can we push the tools we already 
have. 
This model generates a revised version of inputted text with the goal of containing a fewer 
grammatical error. It was trained with Happy Transformer* ( Happy Transformer is a package 
built on top of Hugging Faceâ€™s transformer library that makes it easy to utilize state-of-the-art 
NLP models.) using a dataset called JFLEG**. This model outperforms the human baseline 
on the General Language Understanding Evaluation (GLUE) benchmark- making it one of the 
most powerful NLP models in existence.

![T5 Model](https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s640/image3.gif)

